{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45049,
     "status": "ok",
     "timestamp": 1649765112153,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "bTDZnOe4E1sj",
    "outputId": "0a2da34c-1ba5-463f-93bf-d13d0085f8b3"
   },
   "outputs": [],
   "source": [
    "#初期設定\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lxml\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import tqdm\n",
    "import sys\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://web-kiwami.com/python-beautyfulsoup4.html\n",
    "# http://kondou.com/BS4/\n",
    "# bs4参考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_year\n",
    "this_year = 2022 #年変わったら変更\n",
    "get_year = list(range(2011,this_year+1))\n",
    "df_result = pd.DataFrame()\n",
    "dict1 = {}\n",
    "for year in get_year:\n",
    "    if 2011 <= year <= 2017:\n",
    "        print(year, \"出力中\")\n",
    "        # 単年のデータ取得2011~2017\n",
    "        url =  rf\"https://www.ipokiso.com/company/{year}.html\"\n",
    "        html_res = requests.get(url)\n",
    "        # ページアクセスエラーの出力\n",
    "        if html_res.status_code != 200:\n",
    "            print(\"requests.getでのurlのアクセスができていません\")\n",
    "            lineno = inspect.currentframe().f_lineno\n",
    "            print(f\"エラーが発生しました。行番号: {lineno}\")\n",
    "            sys.exit()\n",
    "        soup = bs4(html_res.content, 'html.parser')\n",
    "        find_all_list = soup.find_all(href=re.compile(\"company/[0-9]{4}/\"))\n",
    "        url_dict = {\n",
    "            find_all_list[i].text:\"https://www.ipokiso.com/\" + find_all_list[i][\"href\"]\n",
    "            for i in range(len(find_all_list))\n",
    "        }\n",
    "        dict1.update(url_dict)\n",
    "        dfs_list = pd.read_html(url)\n",
    "        time.sleep(np.random.randint(100,120)/100)\n",
    "        for i in range(len(dfs_list)):\n",
    "            dfs_list[i][\"上場年\"] = f\"{year}\"\n",
    "            df_result = pd.concat([df_result, dfs_list[i]])\n",
    "            df_result = df_result.reset_index(drop=True)\n",
    "        # df_result.drop(df_result[df_result['企業名'] == \"企業名\"].index , inplace=True)\n",
    "        # df_result.drop(df_result[df_result['初値'] == \"初値\"].index , inplace=True)\n",
    "    else:\n",
    "        # 単年のデータ取得2018~2022\n",
    "        print(year, \"出力中\")\n",
    "        url = rf\"https://www.ipokiso.com/company/{year}.html\"\n",
    "        if year == 2022:\n",
    "            url = r\"https://www.ipokiso.com/company/index.html\"\n",
    "        html_res = requests.get(url)\n",
    "        # ページアクセスエラーの出力\n",
    "        if html_res.status_code != 200:\n",
    "            print(\"requests.getでのurlのアクセスができていません\")\n",
    "            lineno = inspect.currentframe().f_lineno\n",
    "            print(f\"エラーが発生しました。行番号: {lineno}\")\n",
    "            sys.exit()\n",
    "        soup = bs4(html_res.content, 'html.parser')\n",
    "        find_all_list = soup.find_all(href=re.compile(\"company/[0-9]{4}/\"))\n",
    "        url_dict = {\n",
    "            find_all_list[i].text:\"https://www.ipokiso.com/\" + find_all_list[i][\"href\"]\n",
    "            for i in range(len(find_all_list))\n",
    "        }\n",
    "        dict1.update(url_dict)\n",
    "        dfs_list = pd.read_html(url)\n",
    "        # サイト更新時にページのtableのデザインが変更していないかチェック\n",
    "        if year >= 2022:\n",
    "            try:\n",
    "                if dfs_list[0].columns[0] != '企業名':\n",
    "                    raise ValueError(\"銘柄一覧から取得したtableの値が「企業名」ではありません\")\n",
    "                elif dfs_list[1].columns[0] != '総合評価':\n",
    "                    raise ValueError(\"銘柄一覧から取得したtableの値が「総合評価」ではありません\")\n",
    "            except ValueError as e:\n",
    "                # エラーが発生した場合の処理\n",
    "                print(\"Error: {}\".format(e))\n",
    "                lineno = inspect.currentframe().f_lineno\n",
    "                print(f\"エラーが発生した行番号: {lineno}\")   \n",
    "        time.sleep(np.random.randint(100,120)/100)\n",
    "        for i in range(0, len(dfs_list) , 2):\n",
    "            dfs_list_con = pd.concat([dfs_list[i], dfs_list[i+1]], axis=1)\n",
    "            dfs_list_con[\"上場年\"] = f\"{year}\"\n",
    "            if year == 2019:\n",
    "                dfs_list_con = dfs_list_con.rename(columns={'上場 市場': '上場市場'})\n",
    "            if year >= 2020:\n",
    "                dfs_list_con = dfs_list_con.rename(columns={'申し込み期間': '申し込み 期間', '初値上昇率': '初値 上昇率'})\n",
    "            df_result = pd.concat([df_result, dfs_list_con],ignore_index=True)\n",
    "            df_result = df_result.reset_index(drop=True)\n",
    "        df_result.drop(df_result[df_result['企業名'] == \"企業名\"].index , inplace=True)\n",
    "        df_result.drop(df_result[df_result['初値'] == \"初値\"].index , inplace=True)\n",
    "    if year != this_year:\n",
    "        time.sleep(np.random.randint(100,120)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_list[1].columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict作成\n",
    "# 空白削除\n",
    "del dict1[\" \"]\n",
    "del dict1[\"\"]\n",
    "del dict1[\"\\n\"]\n",
    "# dictをdf化\n",
    "df_dict = pd.DataFrame.from_dict(dict1, orient='index')\n",
    "# カラム名変更\n",
    "df_dict = df_dict.rename(columns={0:\"url\"})\n",
    "# 間違えているurlを変更\n",
    "df_dict.url[df_dict.url == \"https://www.ipokiso.com/https://www.ipokiso.com/company/2013/zigexn.html\"] = \"https://www.ipokiso.com/company/2013/zigexn.html\"\n",
    "df_dict = df_dict.rename_axis('index').reset_index()\n",
    "df_dict = df_dict.rename(columns={'index':'company_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時短のためcode含めたcsv読み込み　コード完成後に削除する\n",
    "df_result2 = pd.read_csv(\"df_dict.csv\", index_col=0)\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_listの作成（詳細情報の取得ループ 全てのcode取得[0]までok！\n",
    "def make_company_info(url):\n",
    "    html_res = requests.get(url)\n",
    "    if html_res.status_code != 200:\n",
    "        print(\"requests.getでのurlのアクセスができていません\")\n",
    "        lineno = inspect.currentframe().f_lineno\n",
    "        print(f\"エラーが発生しました。行番号: {lineno}\")\n",
    "        sys.exit()\n",
    "    time.sleep(np.random.randint(100,120)/100)\n",
    "    soup = bs4(html_res.content, 'html.parser')\n",
    "    # 全企業codeの取得\n",
    "    try:\n",
    "        code = re.search(r\"[0-9]{4}\", soup.title.text).group()\n",
    "    except AttributeError:\n",
    "        f = soup.find_all('h1',text=re.compile(r\"[0-9]{4}\"))[0].text\n",
    "        code = re.search(r\"[0-9]{4}\", f).group()\n",
    "    code_list.append(code)\n",
    "    # 成長性等の評価取得\n",
    "    table = soup.find('table',class_=\"company01\")\n",
    "    val = table.find_all('td')\n",
    "    # valからカラムの値に入れたい◎等の値のみ抽出\n",
    "    try:\n",
    "        val_list = []\n",
    "        for i in range(4):\n",
    "            if \">？<\" in str(val[i]):\n",
    "                keyword = \"？\"\n",
    "            elif \"/sannkaku02.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sannkaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sankaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/maru02.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/maru.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/2maru.gif\" in str(val[i]):\n",
    "                keyword = \"◎\"\n",
    "            elif \"/s.gif\" in str(val[i]):\n",
    "                keyword = \"S\"\n",
    "            elif \"/a.gif\" in str(val[i]):\n",
    "                keyword = \"A\"\n",
    "            elif \"/b.gif\" in str(val[i]):\n",
    "                keyword = \"B\"\n",
    "            elif \"/c.gif\" in str(val[i]):\n",
    "                keyword = \"C\"\n",
    "            elif \"/d.gif\" in str(val[i]):\n",
    "                keyword = \"D\"\n",
    "            val_list.append(keyword)\n",
    "    except AttributeError:\n",
    "        val_list = [np.nan,np.nan,np.nan,np.nan]\n",
    "        print(f\"成長性listのエラー{code}\")\n",
    "    evaluation_list.append(val_list)\n",
    "    print(code)\n",
    "code_list = []\n",
    "url_list = df_dict.url.values\n",
    "evaluation_list = []\n",
    "[make_company_info(url) for url in url_list[0:3]] #ここで検証のurl数変更！\n",
    "df_company_01 = pd.DataFrame(evaluation_list,columns=[\"成長性\",\"割安性\",\"話題性\",\"総合評価\"])\n",
    "df_result2[df_company_01.columns] = df_company_01\n",
    "print(df_result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_html(\"https://www.ipokiso.com/company/2021/geolocation.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22612/1209525485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dd[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[7].iloc[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを元に作成2022/12/07~ ↓　i==3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スポーツフィールド（7080）　【東証マザーズ】\n",
      "WDBココ（7079）　【東証マザーズ】\n",
      "AI inside[エーアイインサイド]（4488）　【東証マザーズ】\n",
      "global bridge HOLDINGS[グローバルブリッジホールディングス]（6557）　【東証マザーズ】\n",
      "カクヤス（7686）　【東証2部】\n",
      "スペースマーケット（4487）　【東証マザーズ】\n",
      "ファンペップ（4881）　【東証マザーズ】\n",
      "INCLUSIVE[インクルーシブ]（7078）　【東証マザーズ】\n",
      "SREホールディングス（2980）　【東証マザーズ】\n",
      "ランディックス（2981）　【東証マザーズ】\n",
      "JTOWER[ジェイタワー]（4485）　【東証マザーズ】\n",
      "ユナイトアンドグロウ（4486）　【東証マザーズ】\n",
      "BuySell Technologies[バイセルテクノロジーズ]（7685）　【東証マザーズ】\n",
      "フリー（4478）　【東証マザーズ】\n",
      "ウィルズ（4482）　【東証マザーズ】\n",
      "ベース（4481）　【東証2部】\n",
      "JMDC[ジェイエムディーシー]（4483）　【東証マザーズ】\n",
      "ランサーズ（4484）　【東証マザーズ】\n",
      "メドレー（4480）　【東証マザーズ】\n",
      "マクアケ（4479）　【東証マザーズ】\n",
      "テクノフレックス（3449）　【東証2部】\n",
      "ALiNK[アリンク]インターネット（7077）　【東証マザーズ】\n",
      "名南M&A（7076）　【名証セントレックス】\n",
      "トゥエンティーフォーセブン（7074）　【東証マザーズ】\n",
      "ダブルエー（7683）　【東証マザーズ】\n",
      "恵和[けいわ]（4251）　【東証2部】\n",
      "ジェイック（7073）　【東証マザーズ】\n",
      "セルソース（4880）　【東証マザーズ】\n",
      "BASE（4477）　【東証マザーズ】\n",
      "インティメート・マージャー（7072）　【東証マザーズ】\n",
      "IPO日程と価格決定（初値予想）のdfの値が違ったため、エラーが発生しました\n",
      "浜木綿[はまゆう]（7682）　【JASDAQスタンダード、名証2部】\n",
      "アンビスホールディングス（7071）　【JASDAQスタンダード】\n",
      "AI CROSS［エーアイクロス］（4476）　【東証マザーズ】\n",
      "HENNGE［ヘンゲ］（4475）　【東証マザーズ】\n",
      "レオクラン（7681）　【東証2部】\n",
      "パワーソリューションズ（4450）　【東証マザーズ】\n",
      "HPCシステムズ（6597）　【東証マザーズ】\n",
      "Chatwork［チャットワーク］（4448）　【東証マザーズ】\n",
      "ギフティ（4449）　【東証マザーズ】\n",
      "サイバー・バズ（7069）　【東証マザーズ】\n",
      "アミファ（7800）　【JASDAQスタンダード】\n",
      "ピー・ビーシステムズ（4447）　【福証Qボード】\n",
      "ステムリム（4599）　【東証マザーズ】\n",
      "ツクルバ（2978）　【東証マザーズ】\n",
      "ブシロード（7803）　【東証マザーズ】\n",
      "ビーアンドピー（7804）　【東証マザーズ】\n",
      "Link-U［リンクユー］（4446）　【東証マザーズ】\n",
      "フィードフォース（7068）　【東証マザーズ】\n",
      "リビン・テクノロジーズ（4445）　【東証マザーズ】\n",
      "あさくま（7678）　【JASDAQスタンダード】\n",
      "新日本製薬（4931）　【東証マザーズ】\n",
      "ヤシマキザイ（7677）　【東証2部】\n",
      "インフォネット（4444）　【東証マザーズ】\n",
      "ブランディングテクノロジー（7067）　【東証マザーズ】\n",
      "ピアズ（7066）　【東証マザーズ】\n",
      "Sansan［サンサン］（4443）　【東証マザーズ】\n",
      "日本グランデ（2976）　【札証アンビシャス】\n",
      "ユーピーアール（7065）　【東証2部】\n",
      "大英産業（2974）　【福証】\n",
      "バルテス（4442）　【東証マザーズ】\n",
      "トビラシステムズ（4441）　【東証マザーズ】\n",
      "グッドスピード（7676）　【東証マザーズ】\n",
      "ハウテレビジョン（7064）　【東証マザーズ】\n",
      "ヴィッツ（4440）　【東証マザーズ】\n",
      "東名（4439）　【東証マザーズ・名証セントレックス】\n",
      "Welby［ウェルビー］（4438）　【東証マザーズ】\n",
      "エードット（7063）　【東証マザーズ】\n",
      "NATTY SWANKY［ナッティースワンキー］（7674）　【東証マザーズ】\n",
      "フレアス（7062）　【東証マザーズ】\n",
      "日本ホスピスホールディングス（7061）　【東証マザーズ】\n",
      "gooddays［グッドデイズ］ホールディングス（4437）　【東証マザーズ】\n",
      "ギークス（7060）　【東証マザーズ】\n",
      "コプロ・ホールディングス（7059）　【東証マザーズ、名証セントレックス】\n",
      "ミンカブ・ジ・インフォノイド（4436）　【東証マザーズ】\n",
      "KHC［ケイエイチシー］（1451）　【東証2部】\n",
      "共栄セキュリティーサービス（7058）　【JASDAQスタンダード】\n",
      "カオナビ（4435）　【東証マザーズ】\n",
      "エヌ・シー・エヌ（7057）　【JASDAQスタンダード】\n",
      "サーバーワークス（4434）　【東証マザーズ】\n",
      "ウイングアーク1st（4432）　【東証1部】\n",
      "ダイコー通産（7673）　【東証2部】\n",
      "日本国土開発（1887）　【東証1部】\n",
      "スマレジ（4431）　【東証マザーズ】\n",
      "フロンティアインターナショナル（7050）　【東証マザーズ】\n",
      "東海ソフト（4430）　【東証2部、名証2部】\n",
      "リックソフト（4429）　【東証マザーズ】\n",
      "識学（7049）　【東証マザーズ】\n",
      "オンデック（7360）　【東証マザーズ】\n",
      "クリングルファーマ（4884）　【東証マザーズ】\n",
      "SANEI[サンエイ]（6230）　【東証2部】\n",
      "東和ハイシステム（4172）　【JASDAQスタンダード】\n",
      "東京通信（7359）　【東証マザーズ】\n",
      "グローバルインフォメーション（4171）　【JASDAQスタンダード】\n",
      "交換できるくん（7695）　【東証マザーズ】\n",
      "ENECHANGE[エネチェンジ]（4169）　【東証マザーズ】\n",
      "Kaizen Platform[カイゼン プラットフォーム]（4170）　【東証マザーズ】\n",
      "ウェルスナビ（7342）　【東証マザーズ】\n",
      "ヤプリ（4168）　【東証マザーズ】\n",
      "ポピンズホールディングス（7358）　【東証】\n",
      "いつも（7694）　【東証マザーズ】\n",
      "ココペリ（4167）　【東証マザーズ】\n",
      "かっこ（4166）　【東証マザーズ】\n",
      "オーケーエム（6229）　【東証2部】\n",
      "リベルタ（4935）　【JASDAQスタンダード】\n",
      "ビートレンド（4020）　【東証マザーズ】\n",
      "プレイド（4165）　【東証マザーズ】\n",
      "ローランド（7944）　【東証1部】\n",
      "バルミューダ（6612）　【東証マザーズ】\n",
      "Fast Fitness Japan[ファストフィットネスジャパン]（7092）　【東証マザーズ】\n",
      "スタメン（4019）　【東証マザーズ】\n",
      "ビーイングホールディングス（9145）　【東証2部】\n",
      "バリオセキュア（4494）　【東証2部】\n",
      "クリーマ（4017）　【東証マザーズ】\n",
      "ジオコード（7357）　【JASDAQスタンダード】\n",
      "MITホールディングス（4016）　【JASDAQスタンダード】\n",
      "アララ（4015）　【東証マザーズ】\n",
      "Retty[レッティ]（7356）　【東証マザーズ】\n",
      "さくらさくプラス（7097）　【東証マザーズ】\n",
      "プレミアアンチエイジング（4934）　【東証マザーズ】\n",
      "カラダノート（4014）　【東証マザーズ】\n",
      "アースインフィニティ（7692）　【JASDAQスタンダード】\n",
      "日通システム（4013）　【東証マザーズ】\n",
      "キオクシアホールディングス（6600）　【未定】\n",
      "ダイレクトマーケティングミックス（7354）　【東証1部】\n",
      "タスキ（2987）　【東証マザーズ】\n",
      "アクシス（4012）　【東証マザーズ】\n",
      "ヘッドウォータース（4011）　【東証マザーズ】\n",
      "rakumo[ラクモ]（4060）　【東証マザーズ】\n",
      "I-ne[アイエヌイー]（4933）　【東証マザーズ】\n",
      "STIフードホールディングス（2932）　【東証2部】\n",
      "まぐまぐ（4059）　【JASDAQスタンダード】\n",
      "トヨクモ（4058）　【東証マザーズ】\n",
      "雪国まいたけ（1375）　【東証1部】\n",
      "インターファクトリー（4057）　【東証マザーズ】\n",
      "ニューラルポケット（4056）　【東証マザーズ】\n",
      "ティアンドエス（4055）　【東証マザーズ】\n",
      "モダリス（4883）　【東証マザーズ】\n",
      "Sun Asterisk[サン アスタリスク]（4053）　【東証マザーズ】\n",
      "日本情報クリエイト（4054）　【東証マザーズ】\n",
      "KIYOラーニング（7353）　【東証マザーズ】\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMOフィナンシャルゲート（4051）　【東証マザーズ】\n",
      "Error: 銘柄一覧から取得したtableの値が「株主名」ではありません\n",
      "エラーが発生した行番号: 38\n",
      "エラーが発生したURL:https://www.ipokiso.com//company/2020/gmo-fg.html\n",
      "[   成長性   割安性\n",
      "0  NaN   NaN\n",
      "1  話題性  総合評価\n",
      "2  NaN   NaN,          0                                       1\n",
      "0      会社名            GMOフィナンシャルゲート（4051）　【東証マザーズ】\n",
      "1    会社URL                     https://gmo-fg.com/\n",
      "2  狙い目証券会社  大和証券（主幹事）、SMBC日興証券（副幹事）、GMOクリック証券、DMM株,           0                              1\n",
      "0      想定価格                         2,420円\n",
      "1       仮条件                2,420円 ～ 2,540円\n",
      "2      公募価格                         2,540円\n",
      "3  初値予想（独自）       3,500円 ～ 4,800円（6月29日時点）\n",
      "4        初値  6,550円　（公募価格比+4,010円　+157.9％）,         0                 1\n",
      "0  抽選申込期間  6月30日(火)～7月6日(月)\n",
      "1   当選発表日           7月7日(火)\n",
      "2  購入申込期間  7月8日(水)～7月13日(月)\n",
      "3     上場日          7月15日(水),             0         1\n",
      "0        公募株数  240,000株\n",
      "1  売出株数（OA含む）  276,100株\n",
      "2      当選株数合計  516,100株,       0         1       2         3         4            5\n",
      "0   NaN     証券会社名     割当率      割当株数  当選本数 （枚）  完全抽選本数 （予想）\n",
      "1   主幹事      大和証券  87.02％  449,100株    4,491枚         673枚\n",
      "2    幹事  SMBC日興証券   7.81％   40,300株      403枚          40枚\n",
      "3    幹事     みずほ証券   2.60％   13,400株      134枚          13枚\n",
      "4    幹事    いちよし証券   1.72％    8,900株       89枚           0枚\n",
      "5    幹事      丸三証券   0.85％    4,400株       44枚           4枚\n",
      "6    幹事       NaN     NaN       NaN       NaN          NaN\n",
      "7    幹事       NaN     NaN       NaN       NaN          NaN\n",
      "8    幹事       NaN     NaN       NaN       NaN          NaN\n",
      "9    幹事       NaN     NaN       NaN       NaN          NaN\n",
      "10   幹事       NaN     NaN       NaN       NaN          NaN,                会社名    公募価格                 初値  初値売り 利益     割当株数  当選本数\n",
      "0   GMOメディア （6180）  2,740円   5,510円 （+101.1％）  +27.7万円  39,800株  398枚\n",
      "1  GMO TECH （6026）  5,800円  13,640円 （+135.2％）  +78.4万円  23,400株  234枚\n",
      "2   GMOリサーチ （3695）  2,100円   4,900円 （+133.3％）    +28万円  38,400株  384枚,                           株主名      比率    ロック  アップ\n",
      "0           GMOペイメントゲートウェイ（株）  60.39％       180日間\n",
      "1                 （株）ケイ・エム・シー   5.83％  90日間  1.5倍\n",
      "2      三菱ＵＦＪキャピタル３号投資事業有限責任組合   5.63％  90日間  1.5倍\n",
      "3         大和ベンチャー１号投資事業有限責任組合   4.92％  90日間  1.5倍\n",
      "4                       豊山 慶輔   4.18％  90日間  1.5倍\n",
      "5                        髙野 明   3.29％       180日間\n",
      "6  SMBCベンチャーキャピタル１号投資事業有限責任組合   2.72％  90日間  1.5倍\n",
      "7           みずほ成長支援投資事業有限責任組合   2.05％  90日間  1.5倍\n",
      "8  SMBCベンチャーキャピタル３号投資事業有限責任組合   1.58％  90日間  1.5倍\n",
      "9                       倉田 秀喜   1.30％       180日間,                0        1        2        3        4        5\n",
      "0            NaN  2015年9月  2016年9月  2017年9月  2018年9月  2019年9月\n",
      "1       売上高（百万円）      406      713     1051     1617     2379\n",
      "2      経常利益（百万円）       48       85       93      169      227\n",
      "3     当期純利益（百万円）       47       94       66       90      135\n",
      "4     純資産額 （百万円）      260     2501     2567     2674     3044\n",
      "5  1株あたりの純資産額（円）     6763    20910    21420      744      781\n",
      "6   1株あたりの純利益（円）     1656     2045      551       25       38\n",
      "7      自己資本比率（％）     38.4     67.5     62.9     64.3     57.5\n",
      "8     自己資本利益率（％）     39.0      6.8      2.6      3.4      4.9]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xxp2p\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\", line 32, in make_company_info_2\n",
      "    raise ValueError(\"銘柄一覧から取得したtableの値が「株主名」ではありません\")\n",
      "ValueError: 銘柄一覧から取得したtableの値が「株主名」ではありません\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\xxp2p\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\", line 84, in <module>\n",
      "    df_table_all = make_company_info_2(url)\n",
      "  File \"C:\\Users\\xxp2p\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\", line 42, in make_company_info_2\n",
      "    sys.exit()\n",
      "SystemExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\u001b[0m in \u001b[0;36mmake_company_info_2\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdfs_table_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'株主名'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"銘柄一覧から取得したtableの値が「株主名」ではありません\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"（百万円）\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfs_table_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"（千米ドル）\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfs_table_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 銘柄一覧から取得したtableの値が「株主名」ではありません",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#ここでurl数変更\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mdf_table_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_company_info_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mdf_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_table_all\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22612/3579750937.py\u001b[0m in \u001b[0;36mmake_company_info_2\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs_table_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2068\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[0;32m   2069\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m-> 2070\u001b[1;33m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[0;32m   2071\u001b[0m                                                                      value))\n\u001b[0;32m   2072\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m             out_list = (\n\u001b[1;32m--> 629\u001b[1;33m                 self.structured_traceback(\n\u001b[0m\u001b[0;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xxp2p\\anaconda3\\envs\\yt_38\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# 20221201 ループで全table、全銘柄取り出す。（細かいデータの整形は後でやる）\n",
    "def make_company_info_2(url):\n",
    "    dfs_table_list = pd.read_html(url)\n",
    "    time.sleep(np.random.randint(100,120)/100)\n",
    "    # サイト更新時にデザイン変更がないか検知する（現状ワシントンホテルのみ違うためスルー）\n",
    "    if url != \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "        try:\n",
    "            if dfs_table_list[1].iloc[0,0] != \"会社名\":\n",
    "                raise ValueError(\"銘柄一覧から取得したtableの値が「会社名」ではありません\")\n",
    "            elif dfs_table_list[2].iloc[0,0] != '想定価格':\n",
    "                raise ValueError(\"銘柄一覧から取得したtableの値が「想定価格」ではありません\")               \n",
    "            elif dfs_table_list[3].iloc[0,0] != '抽選申込期間':\n",
    "                raise ValueError(\"銘柄一覧から取得したtableの値が「抽選申込期間」ではありません\")\n",
    "            elif not '公募' in dfs_table_list[4].iloc[0,0]:\n",
    "                raise ValueError(\"銘柄一覧から取得したtableの値が「公募株数等」ではありません\")\n",
    "            elif dfs_table_list[5].iloc[0,1] != '証券会社名':\n",
    "                raise ValueError(\"銘柄一覧から取得したtableの値が「証券会社名」ではありません\")\n",
    "        except ValueError as e:\n",
    "            # エラーが発生した場合の処理\n",
    "            print(\"Error: {}\".format(e))\n",
    "            lineno = inspect.currentframe().f_lineno\n",
    "            print(f\"エラーが発生した行番号: {lineno}\")\n",
    "            print(f\"エラーが発生したURL:{url}\")\n",
    "            print(dfs_table_list)\n",
    "            sys.exit()\n",
    "        # 会社名にREITと投資法人という文字列が無いことを判定する\n",
    "        if not (\"REIT\" in dfs_table_list[1].iloc[0,1]) and not (\"投資法人\" in dfs_table_list[1].iloc[0,1]):\n",
    "            print(dfs_table_list[1].iloc[0,1])\n",
    "            try:\n",
    "                if dfs_table_list[6].columns[0] != '株主名':\n",
    "                    raise ValueError(\"銘柄一覧から取得したtableの値が「株主名」ではありません\")\n",
    "                elif not (\"（百万円）\" in dfs_table_list[7].iloc[1,0]) and not (\"（千米ドル）\" in dfs_table_list[7].iloc[1,0])\t:\n",
    "                    raise ValueError(\"銘柄一覧から取得したtableの値が「財務データ等」ではありません\")\n",
    "            except ValueError as e:\n",
    "                # エラーが発生した場合の処理\n",
    "                print(\"Error: {}\".format(e))\n",
    "                lineno = inspect.currentframe().f_lineno\n",
    "                print(f\"エラーが発生した行番号: {lineno}\")\n",
    "                print(f\"エラーが発生したURL:{url}\")\n",
    "                print(dfs_table_list)\n",
    "                sys.exit()\n",
    "\n",
    "    # ここからdfsの結合、整形コード\n",
    "    for i in range(len(dfs_table_list)):\n",
    "        # 基本情報\n",
    "        if i == 1:\n",
    "            df_table = dfs_table_list[i]\n",
    "            # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "            if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "                df_table = dfs_table_list[i + 1]\n",
    "            # 基本情報のcols取得\n",
    "            cols = df_table.T.values[0]\n",
    "            # 基本情報のval取得\n",
    "            val = df_table.T.values[1]\n",
    "            # 追加する1件分の基本情報のdf作成\n",
    "            df_table_1 = pd.DataFrame([val],columns=cols)\n",
    "        # IPO日程と価格決定（初値予想）\n",
    "        if i == 2:\n",
    "            df_table = dfs_table_list[i]\n",
    "            # ウェブページの変更に対応するためのエラー処理\n",
    "            try:\n",
    "                if df_table.iloc[0,0] != \"想定価格\":\n",
    "                    raise ValueError(\"IPO日程と価格決定（初値予想）のdfの値が違います\")\n",
    "            except ValueError:\n",
    "                print(\"IPO日程と価格決定（初値予想）のdfの値が違ったため、エラーが発生しました\")\n",
    "            # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "            if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "                df_table = dfs_table_list[i + 1]\n",
    "            cols = df_table.T.values[0]\n",
    "            val = df_table.T.values[1]\n",
    "            df_table_2 = pd.DataFrame([val],columns=cols)\n",
    "        # 次ここから\n",
    "        # if i == 3:\n",
    "\n",
    "        # 全件のdfに追加していく\n",
    "    df_table_all = pd.concat([df_table_1,df_table_2],axis=1)\n",
    "    \n",
    "    return df_table_all\n",
    "df_all = pd.DataFrame()\n",
    "url_list = df_dict.url.values\n",
    "for url in url_list[600:]:#ここでurl数変更\n",
    "    df_table_all = make_company_info_2(url) \n",
    "    df_all = pd.concat([df_all,df_table_all],axis=0)\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上本番用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# csv変換 時短のためこれを読み込む\n",
    "df_code = pd.DataFrame(code_list,columns=[\"code\"])\n",
    "df_dict[df_code.columns] = df_code.values\n",
    "df_result2.to_csv(\"df_result2\", encoding='utf-8_sig')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時短のためcode含めたcsv読み込み\n",
    "df_result2 = pd.read_csv(\"df_dict.csv\", index_col=0)\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IPO当選株数のデータ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下データ成長性等取得する\n",
    "url = \"https://www.ipokiso.com//company/2019/washingtonhotel.html\"\n",
    "html_res = requests.get(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "soup = bs4(html_res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table_2011 = pd.read_html(\"https://www.ipokiso.com//company/2019/washingtonhotel.html\")[1]\n",
    "df_html_table_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table = pd.read_html(\"https://www.ipokiso.com/company/2022/tms-japan.html\")\n",
    "df_html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0]の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_01 = pd.DataFrame(evaluation_list,columns=[\"成長性\",\"割安性\",\"話題性\",\"総合評価\"])\n",
    "df_result2[df_company_01.columns] = df_company_01\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_listの作成（詳細情報の取得ループ 全てのcode取得[0]までok！\n",
    "def make_company_info(url):\n",
    "    html_res = requests.get(url)\n",
    "    if html_res.status_code != 200:\n",
    "        print(\"requests.getでのurlのアクセスができていません\")\n",
    "        lineno = inspect.currentframe().f_lineno\n",
    "        print(f\"エラーが発生しました。行番号: {lineno}\")\n",
    "        sys.exit()\n",
    "    time.sleep(np.random.randint(100,120)/100)\n",
    "    soup = bs4(html_res.content, 'html.parser')\n",
    "    # 全企業codeの取得\n",
    "    try:\n",
    "        code = re.search(r\"[0-9]{4}\", soup.title.text).group()\n",
    "    except AttributeError:\n",
    "        f = soup.find_all('h1',text=re.compile(r\"[0-9]{4}\"))[0].text\n",
    "        code = re.search(r\"[0-9]{4}\", f).group()\n",
    "    code_list.append(code)\n",
    "    # 成長性等の評価取得\n",
    "    table = soup.find('table',class_=\"company01\")\n",
    "    val = table.find_all('td')\n",
    "    # valからカラムの値に入れたい◎等の値のみ抽出\n",
    "    try:\n",
    "        val_list = []\n",
    "        for i in range(4):\n",
    "            if \">？<\" in str(val[i]):\n",
    "                keyword = \"？\"\n",
    "            elif \"/sannkaku02.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sannkaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sankaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/maru02.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/maru.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/2maru.gif\" in str(val[i]):\n",
    "                keyword = \"◎\"\n",
    "            elif \"/s.gif\" in str(val[i]):\n",
    "                keyword = \"S\"\n",
    "            elif \"/a.gif\" in str(val[i]):\n",
    "                keyword = \"A\"\n",
    "            elif \"/b.gif\" in str(val[i]):\n",
    "                keyword = \"B\"\n",
    "            elif \"/c.gif\" in str(val[i]):\n",
    "                keyword = \"C\"\n",
    "            elif \"/d.gif\" in str(val[i]):\n",
    "                keyword = \"D\"\n",
    "            else:\n",
    "                keyword = np.nan\n",
    "            val_list.append(keyword)\n",
    "    except AttributeError:\n",
    "        val_list = [np.nan,np.nan,np.nan,np.nan]\n",
    "        print(f\"成長性listのエラー{code}\")\n",
    "    evaluation_list.append(val_list)\n",
    "    print(code)\n",
    "code_list = []\n",
    "url_list = df_dict.url.values\n",
    "evaluation_list = []\n",
    "[make_company_info(url) for url in url_list[0:3]] #ここで検証のurl数変更！\n",
    "df_company_01 = pd.DataFrame(evaluation_list,columns=[\"成長性\",\"割安性\",\"話題性\",\"総合評価\"])\n",
    "df_result2[df_company_01.columns] = df_company_01\n",
    "print(df_result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2.to_csv(\"df_result2.csv\", encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全table取得（pd_htmlによる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table[2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_html_table[2].T.values[0]\n",
    "# 基本情報のval取得\n",
    "val = df_html_table[2].T.values[1]\n",
    "# 追加する1件分の基本情報のdf作成\n",
    "df_table_1 = pd.DataFrame([val],columns=cols)\n",
    "df_table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_html_table[3].T.values[0]\n",
    "# 基本情報のval取得\n",
    "val = df_html_table[3].T.values[1]\n",
    "# 追加する1件分の基本情報のdf作成\n",
    "df_table_2 = pd.DataFrame([val],columns=cols)\n",
    "df_table_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_html_table[4].T.values[0]\n",
    "# 基本情報のval取得\n",
    "val = df_html_table[4].T.values[1]\n",
    "# 追加する1件分の基本情報のdf作成\n",
    "df_table_3 = pd.DataFrame([val],columns=cols)\n",
    "df_table_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table[5].T.values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_html_table[5].T.values[0]\n",
    "# 基本情報のval取得\n",
    "val = df_html_table[5].T.values[1]\n",
    "# 追加する1件分の基本情報のdf作成\n",
    "df_table_4 = pd.DataFrame([val],columns=cols)\n",
    "df_table_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_table_1,df_table_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all.empty == True:\n",
    "    print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all,df_table_all],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_all = pd.merge(df_table_1,df_table_2,on=[\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20221201 ループで全table、全銘柄取り出す。（細かいデータの整形は後でやる）\n",
    "def make_company_info(url):\n",
    "    df_html_table = pd.read_html(url)\n",
    "    for i in range(0,8):\n",
    "\n",
    "        # 基本情報\n",
    "        if i == 0:\n",
    "            df_table = df_html_table[i + 1]\n",
    "            # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "            if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "                df_table = df_html_table[i + 2]\n",
    "            # 基本情報のcols取得\n",
    "            cols = df_table.T.values[0]\n",
    "            # 基本情報のval取得\n",
    "            val = df_table.T.values[1]\n",
    "            # 追加する1件分の基本情報のdf作成\n",
    "            df_table_1 = pd.DataFrame([val],columns=cols)\n",
    "        # IPO日程と価格決定（初値予想）\n",
    "        if i == 1:\n",
    "            df_table = df_html_table[i + 1]\n",
    "            # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "            if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "                df_table = df_html_table[i + 2]\n",
    "            cols = df_table.T.values[0]\n",
    "            val = df_table.T.values[1]\n",
    "            df_table_2 = pd.DataFrame([val],columns=cols)\n",
    "        # 次ここから\n",
    "        # if i == 2:\n",
    "\n",
    "        # 全件のdfに追加していく\n",
    "    df_table_all = pd.concat([df_table_1,df_table_2],axis=1)\n",
    "    \n",
    "    return df_table_all\n",
    "df_all = pd.DataFrame()\n",
    "code_list = []\n",
    "url_list = df_dict.url.values\n",
    "evaluation_list = []\n",
    "for url in url_list[0:3]:\n",
    "    df_table_all = make_company_info(url)\n",
    "    df_all = pd.concat([df_all,df_table_all],axis=0)\n",
    "# df = [make_company_info(url) for url in url_list[0:3]] #ここで検証のurl数変更！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table_2011 = pd.read_html(\"https://www.ipokiso.com//company/2019/washingtonhotel.html\")\n",
    "cols = df_html_table_2011.T.values[0]\n",
    "val = df_html_table_2011.T.values[1]\n",
    "df_basic_info2 = pd.DataFrame([val],columns=cols)\n",
    "df_basic_info2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table_2011 = pd.read_html(\"https://www.ipokiso.com//company/2019/washingtonhotel.html\")[1]\n",
    "cols = df_html_table_2011.T.values[0]\n",
    "val = df_html_table_2011.T.values[1]\n",
    "df_basic_info = pd.DataFrame([val],columns=cols)\n",
    "df_basic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table_2011 = pd.read_html(\"https://www.ipokiso.com//company/2019/washingtonhotel.html\")\n",
    "\n",
    "df_html_table_2011[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時短のためcode含めたcsv読み込み\n",
    "df_result2 = pd.read_csv(\"df_dict.csv\", index_col=0)\n",
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 202221130\n",
    "def make_company_info(url):\n",
    "    html_res = requests.get(url)\n",
    "    if html_res.status_code != 200:\n",
    "        print(\"requests.getでのurlのアクセスができていません\")\n",
    "        lineno = inspect.currentframe().f_lineno\n",
    "        print(f\"エラーが発生しました。行番号: {lineno}\")\n",
    "        sys.exit()\n",
    "    time.sleep(np.random.randint(100,120)/100)\n",
    "    soup = bs4(html_res.content, 'html.parser')\n",
    "    # 全企業codeの取得\n",
    "    try:\n",
    "        code = re.search(r\"[0-9]{4}\", soup.title.text).group()\n",
    "    except AttributeError:\n",
    "        f = soup.find_all('h1',text=re.compile(r\"[0-9]{4}\"))[0].text\n",
    "        code = re.search(r\"[0-9]{4}\", f).group()\n",
    "    code_list.append(code)\n",
    "    # table[0]成長性等の評価取得\n",
    "    table = soup.find('table',class_=\"company01\")\n",
    "    val = table.find_all('td')\n",
    "    # valからカラムの値に入れたい◎等の値のみ抽出\n",
    "    try:\n",
    "        val_list = []\n",
    "        for i in range(4):\n",
    "            if \">？<\" in str(val[i]):\n",
    "                keyword = \"？\"\n",
    "            elif \"/sannkaku02.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sannkaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/sankaku.gif\" in str(val[i]):\n",
    "                keyword = \"△\"\n",
    "            elif \"/maru02.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/maru.gif\" in str(val[i]):\n",
    "                keyword = \"〇\"\n",
    "            elif \"/2maru.gif\" in str(val[i]):\n",
    "                keyword = \"◎\"\n",
    "            elif \"/s.gif\" in str(val[i]):\n",
    "                keyword = \"S\"\n",
    "            elif \"/a.gif\" in str(val[i]):\n",
    "                keyword = \"A\"\n",
    "            elif \"/b.gif\" in str(val[i]):\n",
    "                keyword = \"B\"\n",
    "            elif \"/c.gif\" in str(val[i]):\n",
    "                keyword = \"C\"\n",
    "            elif \"/d.gif\" in str(val[i]):\n",
    "                keyword = \"D\"\n",
    "            else:\n",
    "                keyword = np.nan\n",
    "            val_list.append(keyword)\n",
    "    except AttributeError:\n",
    "        val_list = [np.nan,np.nan,np.nan,np.nan]\n",
    "        print(f\"成長性listのエラー{code}\")\n",
    "    evaluation_list.append(val_list)\n",
    "\n",
    "    # read_htmlでtable情報取得\n",
    "    df_html_table = pd.read_html(url)\n",
    "\n",
    "    #[1]基本情報\n",
    "    # 関数外の変数が取れないためglobalで定義する\n",
    "    global df_basic_info\n",
    "    time.sleep(np.random.randint(100,120)/100)\n",
    "    for i in range(1,8):\n",
    "        df_table = df_html_table[1 + i].copy()\n",
    "        # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "        if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "            df_table = df_html_table[2 + i].copy()\n",
    "        # 基本情報のcols取得\n",
    "        cols = df_table.T.values[0]\n",
    "        # 基本情報のval取得\n",
    "        val = df_table.T.values[1]\n",
    "        # 追加する1件分の基本情報のdf作成\n",
    "        df_table_new = pd.DataFrame([val],columns=cols)\n",
    "        print(df_table_new)\n",
    "        # 全件のdfに追加していく\n",
    "        # df_basic_info = pd.merge([df_basic_info,df_table_new])\n",
    "        return df_basic_info\n",
    "\n",
    "    \"\"\"\n",
    "    # table基本情報のみ取取得\n",
    "    df_table_basic = df_html_table[1].copy()\n",
    "    # ワシントンホテルのみ[1]に優待情報があるためtableをずらしている\n",
    "    if url == \"https://www.ipokiso.com//company/2019/washingtonhotel.html\":\n",
    "        df_table_basic = df_html_table[2].copy()\n",
    "    # 基本情報のcols取得\n",
    "    cols = df_table_basic.T.values[0]\n",
    "    # 基本情報のval取得\n",
    "    val = df_table_basic.T.values[1]\n",
    "    # 追加する1件分の基本情報のdf作成\n",
    "    df_basic_info_new = pd.DataFrame([val],columns=cols)\n",
    "    # 全件のdfに追加していく\n",
    "    df_basic_info = pd.concat([df_basic_info,df_basic_info_new],ignore_index=True)\n",
    "    print(code)\n",
    "    print(evaluation_list)\n",
    "    return df_basic_info\n",
    "    \"\"\"\n",
    "    \n",
    "code_list = []\n",
    "url_list = df_dict.url.values\n",
    "evaluation_list = []\n",
    "\n",
    "\n",
    "# 基本情報の空df作成\n",
    "df_basic_info = pd.DataFrame([],columns=[\"会社名\",\"コード\",\"市場\",\"会社URL\",\"狙い目証券会社\",\"会社設立\"])\n",
    "[make_company_info(url) for url in url_list[range(3)]] #ここで検証のurl数変更！\n",
    "df_company_01 = pd.DataFrame(evaluation_list,columns=[\"成長性\",\"割安性\",\"話題性\",\"総合評価\"])\n",
    "df_result2[df_company_01.columns] = df_company_01\n",
    "#[1]データ分割、整理、結合　codeの場所を分ける？ \n",
    "# 結合(axis=1で横方向の結合)\n",
    "df_result2 = pd.concat([df_result2,df_basic_info],axis=1)\n",
    "\n",
    "\n",
    "print(df_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic_info.to_csv(\"df_basic_info.csv\", encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7]の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降参考データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html_table.T.iloc[1:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_html_table = pd.read_html(\"https://www.ipokiso.com/company/2022/tms-japan.html\")[4]\n",
    "\n",
    "cols = df_html_table.T.iloc[0,:].values\n",
    "val = df_html_table.T.iloc[1:,:].values.flatten()\n",
    "df_ipo_stock_info = pd.DataFrame([val],columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.subで文字列置換している　(arr.split(\"株\")[i])の文字列のr'/D'に一致したものを''に置換する\n",
    "# \\Dは数字以外の文字列\n",
    "# splitで株で区切って株自体は消す。配列にいれる\n",
    "# intで数字に変換\n",
    "stock_info = [\n",
    "    int(re.sub( r'\\D', '', (arr.split(\"株\")[i]))) \n",
    "    for arr in val\n",
    "    for i in range(3) \n",
    "]\n",
    "# ravelは配列を一次元化する\n",
    "# ravel()は可能な限りビューを返すが、flatten()は常にコピーを返すという違いがある。\n",
    "# カラムを２つ国内と海外を作成してリスト化、1次元化している。\n",
    "cols_1 = np.ravel([[c,c+\"_国内\",c+\"_海外\"] for c in cols])\n",
    "# 分割したデータと、名称を変更したカラムでデータフレームを作成している。\n",
    "df_stock_info = pd.DataFrame([stock_info],columns=cols_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以後チェック用code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLdict（単年）作成 確認用\n",
    "year = \"2020\"\n",
    "url = f'https://www.ipokiso.com/company/{year}.html'\n",
    "html_res = requests.get(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "soup = bs4(html_res.content, 'html.parser')\n",
    "find_all_list = soup.find_all(href=re.compile(f\"company/{year}/\"))\n",
    "url_dict = {\n",
    "    find_all_list[i].text:\"https://www.ipokiso.com/\" + soup.find_all(href=re.compile(f\"company/{year}/\"))[i][\"href\"]\n",
    "    for i in range(len(find_all_list))\n",
    "}\n",
    "url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単年のデータ取得2011~2017　確認用\n",
    "df_result = pd.DataFrame()\n",
    "year = \"2011\"\n",
    "url =  rf\"https://www.ipokiso.com/company/{year}.html\"\n",
    "html_res = requests.get(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "soup = bs4(html_res.content, 'html.parser')\n",
    "find_all_list = soup.find_all(href=re.compile(f\"company/{year}/\"))\n",
    "print(len(find_all_list))\n",
    "df_url = pd.read_html(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "for i in range(len(df_url)):\n",
    "    df_url[i][\"上場年\"] = f\"{year}\"\n",
    "    df_result = pd.concat([df_result, df_url[i]])\n",
    "    df_result = df_result.reset_index(drop=True)\n",
    "df_result.drop(df_result[df_result['企業名'] == \"企業名\"].index , inplace=True)\n",
    "df_result.drop(df_result[df_result['初値'] == \"初値\"].index , inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単年のデータ取得2018~2022　確認用\n",
    "df_result = pd.DataFrame()\n",
    "year = \"2022\"\n",
    "url =  rf\"https://www.ipokiso.com/company/{year}.html\"\n",
    "if year == \"2022\":\n",
    "    url =  r\"https://www.ipokiso.com/company/index.html\"\n",
    "html_res = requests.get(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "soup = bs4(html_res.content, 'html.parser')\n",
    "find_all_list = soup.find_all(href=re.compile(f\"company/{year}/\"))\n",
    "print(len(find_all_list))\n",
    "df_url = pd.read_html(url)\n",
    "time.sleep(np.random.randint(100,120)/100)\n",
    "for i in range(0, len(df_url) , 2):\n",
    "    df_url_con = pd.concat([df_url[i], df_url[i+1]], axis=1)\n",
    "    df_url_con[\"上場年\"] = f\"{year}\"\n",
    "    df_result = pd.concat([df_result, df_url_con],ignore_index=True)\n",
    "    df_result = df_result.reset_index(drop=True)\n",
    "df_result.drop(df_result[df_result['企業名'] == \"企業名\"].index , inplace=True)\n",
    "df_result.drop(df_result[df_result['初値'] == \"初値\"].index , inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649765151107,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "0NxwYzXoo5NZ"
   },
   "outputs": [],
   "source": [
    "\"\"\"ArithmeticErrordf = df.drop_duplicates()\n",
    "#カラムの重複した行を消す。\n",
    "df = df[(df['申込日'] != \"申込日\").values].reset_index(drop=1)\n",
    "#index番号をリセットする。\n",
    "col = ['申込日', '株数', '前週比', '金額', '前週比.1', '株数.1', '前週比.1.1', '金額.1', '前週比.1.2','評価損益率(%)', '信用倍率']\n",
    "df.columns = col\n",
    "#columns（カラムズ）パラメータで列名を自分で指定し修正する。\n",
    "#2重になってたカラムも一つに統一できる。MultiIndex⇒Indexにパラメータを変更。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1649765151600,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "DcZVZk_MXtgY"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(r\"C:\\Users\\xxp2p\\OneDrive\\ドキュメント\\MEGA_saya\\Traders_web\\margin_transition\\csv\\margin_transition.csv\", encoding='utf-8_sig')\n",
    "#文字化け改善 encoding='utf-8_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#読み込み\n",
    "# pd.read_csv(r\"C:\\Users\\xxp2p\\OneDrive\\ドキュメント\\MEGA_saya\\Traders_web\\margin_transition\\csv\\margin_transition.csv\", header=None, na_values=['-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649765151603,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "LpDIiO4dPNEd"
   },
   "outputs": [],
   "source": [
    "#Pythonの文字列を拡張するf,r,b,uについて\n",
    "#f… .format()を使うことなく文字列の中に変数を埋め込むことができる。\n",
    "#r… raw string　通常はバックスラッシュ（改行）があった場合エスケープシーケンスが働くが、raw stringを用いることで無視。\n",
    "#b…バイト列リテラル str型ではなくバイト型のインスタンスを作成します。\n",
    "#u…Unicodeに変換する\n",
    "#fとrだけ使えればOK！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649765151604,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "uk6gJjEnUul8"
   },
   "outputs": [],
   "source": [
    "#縦方向に結合する方法|append(), concat()  参考URL https://obgynai.com/python-pandas-index-merge-join/\n",
    "#append：新しい行を追加するメソッド  \n",
    "#concat：columns(列名)や index (行名)を参照して結合するメソッド。ignore_indexとはindexを無視するという意味。concatでデータフレームを結合した際にindexに付与された番号を無視すると言う事になる。\n",
    "#drop dropで行を削除する  参考URL　https://www.sejuku.net/blog/73830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649765151605,
     "user": {
      "displayName": "樅山輝",
      "userId": "13613188553709245558"
     },
     "user_tz": -540
    },
    "id": "m2HbwYbx19J6"
   },
   "outputs": [],
   "source": [
    "#データのスクレイピングとデータ整形のコードは分ける。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9QJ928E/05bykGRGqoQZJ",
   "collapsed_sections": [],
   "name": "traders信用残スクレイピング火曜実行.ipynb",
   "provenance": [
    {
     "file_id": "1eZpjfsHF_ERrNbbJ-uq9B6uDR4SXxpmi",
     "timestamp": 1644795749671
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c94bdebe17f03cae7fda76860c6ff1bbe2feabe4a32a304bbf36a54ab3aac08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
